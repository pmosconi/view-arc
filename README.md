# View Arc Obstacle Detection

Finds the obstacle with largest visible angular coverage within a field-of-view arc from a viewer point.

## Installation

```bash
uv venv --python 3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

For development:
```bash
uv pip install -e ".[dev]"
```

## Usage

The quickest way to see the API in action is to run the bundled basic example:

```bash
uv run python examples/basic_usage.py
```

This prints a human-readable summary generated by the richly documented
``ObstacleResult`` class. You can also copy the minimal pattern below into
your own project:

```python
import numpy as np
from view_arc import find_largest_obstacle

viewer = np.array([100.0, 100.0], dtype=np.float32)
view_direction = np.array([0.0, 1.0], dtype=np.float32)  # unit vector
field_of_view_deg = 60.0
max_range = 150.0
contours = [
    np.array([[90.0, 150.0], [110.0, 150.0], [100.0, 190.0]], dtype=np.float32),
    np.array([[70.0, 130.0], [130.0, 130.0], [130.0, 180.0], [70.0, 180.0]], dtype=np.float32),
]

result = find_largest_obstacle(
    viewer_point=viewer,
    view_direction=view_direction,
    field_of_view_deg=field_of_view_deg,
    max_range=max_range,
    obstacle_contours=contours,
    return_intervals=True,
)

print(result.summary())
```

All public functions in the package include comprehensive docstrings that you
can explore via ``help(view_arc.find_largest_obstacle)``.

## Examples

- ``examples/basic_usage.py`` – minimal, self-contained invocation with console output.
- ``examples/visualization_demo.py`` – renders the wedge, obstacles, and resolved intervals to ``examples/output/visualization_demo.png`` (requires OpenCV).
- ``examples/real_image_processing.py`` – extracts contours from the ``skimage`` astronaut image, runs detection, and saves an annotated overlay.

Run every example with ``uv run python <script>`` so that dependencies resolve inside the project environment.

## Tracking Assumptions

Temporal attention tracking (see `docs/TRACKING_PLAN.md`) relies on two upstream guarantees that we do **not** re-validate at runtime:
- Viewer samples arrive exactly at 1 Hz, so each accepted hit represents one second of attention.
- Viewer positions, directions, and AOI contours all share the same immutable image-coordinate space for the entire batch.

Any pipeline feeding `compute_attention_seconds()` must uphold these invariants to keep the reported metrics meaningful.

## Type Checking

Mypy is configured with ``disallow_untyped_defs`` and must remain clean:

```bash
uv run mypy .
```

Address any type errors before committing changes.

## Algorithm

See `docs/obstacle_arc_spec.md` for detailed algorithm specification.
